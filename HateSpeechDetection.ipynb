{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "uGA50PNxdvtI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JXgBxCvcagV7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 0: NLTK setup"
      ],
      "metadata": {
        "id": "1R7qhn5Md9mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    print(\"NLTK data not found. Downloading...\")\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('punkt')\n",
        "    print(\"Download complete.\")"
      ],
      "metadata": {
        "id": "DL5vTuGaa5Gk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22510b50-fb72-4f12-e4cd-ac18e2f2c844"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK data not found. Downloading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Data Loading & Preparation"
      ],
      "metadata": {
        "id": "D0EwKyxweNBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(\"--- Step 1: Data Loading & Preparation ---\")\n",
        "try:\n",
        "    data_df = pd.read_csv(r\"/content/train (1).csv\")\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: CSV file not found. Please check the path.\")\n",
        "    exit()\n",
        "\n",
        "# Map the `class` column (0,1,2) into binary labels\n",
        "# 0 = Hate Speech → Offensive\n",
        "# 1 = Offensive Language → Offensive\n",
        "# 2 = Neither → Not Offensive\n",
        "if 'class' not in data_df.columns:\n",
        "    print(\"Available columns:\", data_df.columns.tolist())\n",
        "    exit()\n",
        "\n",
        "data_df['labels'] = data_df['class'].map({\n",
        "    0: 'Offensive/Hate Speech',\n",
        "    1: 'Offensive/Hate Speech',\n",
        "    2: 'Not Offensive'\n",
        "})\n",
        "\n",
        "data_df = data_df[['tweet', 'labels']]\n",
        "print(\"\\nPrepared Data:\")\n",
        "print(data_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0POtgoFbDw7",
        "outputId": "cea69985-afa4-40fb-8944-6e6574fdadf4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Data Loading & Preparation ---\n",
            "Dataset loaded successfully.\n",
            "\n",
            "Prepared Data:\n",
            "                                               tweet                 labels\n",
            "0  !!! RT @mayasolovely: As a woman you shouldn't...          Not Offensive\n",
            "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  Offensive/Hate Speech\n",
            "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  Offensive/Hate Speech\n",
            "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  Offensive/Hate Speech\n",
            "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  Offensive/Hate Speech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Text Preprocessing"
      ],
      "metadata": {
        "id": "CKOmyUN8emGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Step 2: Text Preprocessing ---\")\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "important_words = {\n",
        "    \"i\",\"am\",\"you\",\"we\",\"he\",\"she\",\"they\",\"my\",\"your\",\n",
        "    \"love\",\"like\",\"good\",\"nice\",\"happy\",\"great\",\"friend\"\n",
        "}\n",
        "filtered_stopwords = stop_words - important_words\n",
        "\n",
        "def clean_tweet(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    cleaned_words = [\n",
        "        stemmer.stem(word) for word in text.split() if word not in filtered_stopwords\n",
        "    ]\n",
        "    return ' '.join(cleaned_words)\n",
        "\n",
        "data_df['tweet'] = data_df['tweet'].apply(clean_tweet)\n",
        "print(\"Text cleaning and stemming complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Job-b6yibmz9",
        "outputId": "05a8af74-7131-479d-9d9e-3ea79d027670"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 2: Text Preprocessing ---\n",
            "Text cleaning and stemming complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Balance Dataset"
      ],
      "metadata": {
        "id": "eqAqhZvbevrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Step 3: Balancing Dataset ---\")\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "majority = data_df[data_df['labels'] == \"Offensive/Hate Speech\"]\n",
        "minority = data_df[data_df['labels'] == \"Not Offensive\"]\n",
        "\n",
        "# Upsample minority\n",
        "minority_upsampled = resample(minority,\n",
        "                              replace=True,\n",
        "                              n_samples=len(majority),\n",
        "                              random_state=42)\n",
        "\n",
        "balanced_df = pd.concat([majority, minority_upsampled])\n",
        "print(\"Balanced class distribution:\")\n",
        "print(balanced_df['labels'].value_counts())\n",
        "\n",
        "x = balanced_df['tweet']\n",
        "y = balanced_df['labels']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.3, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhFmLUlCbujs",
        "outputId": "df0c4ade-9896-4760-b7c2-15bd475e85cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 3: Balancing Dataset ---\n",
            "Balanced class distribution:\n",
            "labels\n",
            "Offensive/Hate Speech    20620\n",
            "Not Offensive            20620\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Train Model"
      ],
      "metadata": {
        "id": "nbLvTURVfkG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Step 4: Training Model ---\")\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1,2), min_df=3, max_df=0.9)),\n",
        "    ('clf', SGDClassifier(\n",
        "        loss=\"log_loss\",\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=42,\n",
        "        max_iter=2000,\n",
        "        tol=1e-4\n",
        "    ))\n",
        "])\n",
        "\n",
        "pipeline.fit(x_train, y_train)\n",
        "print(\"Model trained successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE-oCVV0b4Pa",
        "outputId": "5e3f1ae4-3504-431c-ef6d-ab471c000750"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 4: Training Model ---\n",
            "Model trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Model Evaluation"
      ],
      "metadata": {
        "id": "CBjUkfEjfrI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Step 5: Model Evaluation ---\")\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "y_pred = pipeline.predict(x_test)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJnaGRuQcByU",
        "outputId": "62b6705b-29aa-4410-9920-9534b773ee13"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 5: Model Evaluation ---\n",
            "Accuracy: 0.9528\n",
            "\n",
            "Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "        Not Offensive       0.93      0.98      0.95      6186\n",
            "Offensive/Hate Speech       0.98      0.93      0.95      6186\n",
            "\n",
            "             accuracy                           0.95     12372\n",
            "            macro avg       0.95      0.95      0.95     12372\n",
            "         weighted avg       0.95      0.95      0.95     12372\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Saving and loading Model"
      ],
      "metadata": {
        "id": "8aoiqypnftha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(pipeline, \"hsd_model.joblib\")\n",
        "print(\"✅ Model saved successfully as hsd_model.joblib\")\n",
        "\n",
        "# Load the model back\n",
        "loaded_model = joblib.load(\"hsd_model.joblib\")\n",
        "print(\"✅ Model loaded successfully with joblib\")\n"
      ],
      "metadata": {
        "id": "t51xYzxycGL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b351ea49-403f-4662-834c-d66632c7bb0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved successfully as hsd_model.joblib\n",
            "✅ Model loaded successfully with joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Interactive Prediction"
      ],
      "metadata": {
        "id": "TF9Wg3OldaYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Step 7: Interactive Prediction ---\")\n",
        "positive_words = {\"love\", \"nice\", \"good\", \"happy\", \"great\", \"friend\", \"beautiful\"}\n",
        "\n",
        "def custom_predict(text):\n",
        "    base_pred = pipeline.predict([text])[0]\n",
        "    proba = pipeline.predict_proba([text])[0]\n",
        "\n",
        "    # Positive safeguard\n",
        "    if any(word in text.lower() for word in positive_words):\n",
        "        not_off_idx = list(pipeline.classes_).index(\"Not Offensive\")\n",
        "        if proba[not_off_idx] < 0.6:\n",
        "            base_pred = \"Not Offensive\"\n",
        "\n",
        "    return base_pred, dict(zip(pipeline.classes_, proba))\n",
        "\n",
        "print(\"Enter a phrase to check if it's hate speech (type 'quit' to exit):\")\n",
        "while True:\n",
        "    user_input = input(\"Enter text: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "    pred, probas = custom_predict(user_input)\n",
        "    print(f\"\\nPrediction: {pred}\")\n",
        "    print(\"Confidence Scores:\")\n",
        "    for label, prob in probas.items():\n",
        "        print(f\"  {label}: {prob:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyvJypQMcNKx",
        "outputId": "67daf811-89af-4143-e8af-6184eca9af0b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Step 7: Interactive Prediction ---\n",
            "Enter a phrase to check if it's hate speech (type 'quit' to exit):\n",
            "Enter text: i love to cook fruits\n",
            "\n",
            "Prediction: Not Offensive\n",
            "Confidence Scores:\n",
            "  Not Offensive: 0.7945\n",
            "  Offensive/Hate Speech: 0.2055\n",
            "Enter text: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_predict(text):\n",
        "    base_pred = loaded_model.predict([text])[0]\n",
        "    proba = loaded_model.predict_proba([text])[0]\n",
        "\n",
        "    # Positive safeguard\n",
        "    if any(word in text.lower() for word in positive_words):\n",
        "        not_off_idx = list(loaded_model.classes_).index(\"Not Offensive\")\n",
        "        if proba[not_off_idx] < 0.6:\n",
        "            base_pred = \"Not Offensive\"\n",
        "\n",
        "    return base_pred, dict(zip(loaded_model.classes_, proba))\n",
        "\n",
        "print(\"Enter a phrase to check if it's hate speech (type 'quit' to exit):\")\n",
        "while True:\n",
        "    user_input = input(\"Enter text: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "    pred, probas = custom_predict(user_input)\n",
        "    print(f\"\\nPrediction: {pred}\")\n",
        "    print(\"Confidence Scores:\")\n",
        "    for label, prob in probas.items():\n",
        "        print(f\"  {label}: {prob:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCjf6DkAbswA",
        "outputId": "68cd6f43-9ffc-43de-99dd-5e99e690e4ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a phrase to check if it's hate speech (type 'quit' to exit):\n",
            "Enter text: quit\n"
          ]
        }
      ]
    }
  ]
}