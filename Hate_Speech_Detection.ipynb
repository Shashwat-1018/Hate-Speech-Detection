{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "uGA50PNxdvtI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXgBxCvcagV7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 0: NLTK setup"
      ],
      "metadata": {
        "id": "1R7qhn5Md9mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    print(\"NLTK data not found. Downloading...\")\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('punkt')\n",
        "    print(\"Download complete.\")"
      ],
      "metadata": {
        "id": "DL5vTuGaa5Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Data Loading & Preparation"
      ],
      "metadata": {
        "id": "D0EwKyxweNBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(\"--- Step 1: Data Loading & Preparation ---\")\n",
        "try:\n",
        "    data_df = pd.read_csv(r\"/content/train (1).csv\")\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: CSV file not found. Please check the path.\")\n",
        "    exit()\n",
        "\n",
        "# Map the `class` column (0,1,2) into binary labels\n",
        "# 0 = Hate Speech → Offensive\n",
        "# 1 = Offensive Language → Offensive\n",
        "# 2 = Neither → Not Offensive\n",
        "if 'class' not in data_df.columns:\n",
        "    print(\"Available columns:\", data_df.columns.tolist())\n",
        "    exit()\n",
        "\n",
        "data_df['labels'] = data_df['class'].map({\n",
        "    0: 'Offensive/Hate Speech',\n",
        "    1: 'Offensive/Hate Speech',\n",
        "    2: 'Not Offensive'\n",
        "})\n",
        "\n",
        "data_df = data_df[['tweet', 'labels']]\n",
        "print(\"\\nPrepared Data:\")\n",
        "print(data_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0POtgoFbDw7",
        "outputId": "201fb4eb-aac1-4dc4-ff53-a888e94c39ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Data Loading & Preparation ---\n",
            "Dataset loaded successfully.\n",
            "\n",
            "Prepared Data:\n",
            "                                               tweet                 labels\n",
            "0  !!! RT @mayasolovely: As a woman you shouldn't...          Not Offensive\n",
            "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  Offensive/Hate Speech\n",
            "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  Offensive/Hate Speech\n",
            "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  Offensive/Hate Speech\n",
            "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  Offensive/Hate Speech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Text Preprocessing"
      ],
      "metadata": {
        "id": "CKOmyUN8emGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Step 2: Text Preprocessing ---\")\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "important_words = {\n",
        "    \"i\",\"am\",\"you\",\"we\",\"he\",\"she\",\"they\",\"my\",\"your\",\n",
        "    \"love\",\"like\",\"good\",\"nice\",\"happy\",\"great\",\"friend\"\n",
        "}\n",
        "filtered_stopwords = stop_words - important_words\n",
        "\n",
        "def clean_tweet(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    cleaned_words = [\n",
        "        stemmer.stem(word) for word in text.split() if word not in filtered_stopwords\n",
        "    ]\n",
        "    return ' '.join(cleaned_words)\n",
        "\n",
        "data_df['tweet'] = data_df['tweet'].apply(clean_tweet)\n",
        "print(\"Text cleaning and stemming complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Job-b6yibmz9",
        "outputId": "5322e2b4-831f-4e44-8730-66e0d9a2e771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 2: Text Preprocessing ---\n",
            "Text cleaning and stemming complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Balance Dataset"
      ],
      "metadata": {
        "id": "eqAqhZvbevrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Step 3: Balancing Dataset ---\")\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "majority = data_df[data_df['labels'] == \"Offensive/Hate Speech\"]\n",
        "minority = data_df[data_df['labels'] == \"Not Offensive\"]\n",
        "\n",
        "# Upsample minority\n",
        "minority_upsampled = resample(minority,\n",
        "                              replace=True,\n",
        "                              n_samples=len(majority),\n",
        "                              random_state=42)\n",
        "\n",
        "balanced_df = pd.concat([majority, minority_upsampled])\n",
        "print(\"Balanced class distribution:\")\n",
        "print(balanced_df['labels'].value_counts())\n",
        "\n",
        "x = balanced_df['tweet']\n",
        "y = balanced_df['labels']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.3, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhFmLUlCbujs",
        "outputId": "254c370a-2751-457a-fb14-dcd5595bbd24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 3: Balancing Dataset ---\n",
            "Balanced class distribution:\n",
            "labels\n",
            "Offensive/Hate Speech    20620\n",
            "Not Offensive            20620\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Train Model"
      ],
      "metadata": {
        "id": "nbLvTURVfkG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Step 4: Training Model ---\")\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1,2), min_df=3, max_df=0.9)),\n",
        "    ('clf', SGDClassifier(\n",
        "        loss=\"log_loss\",\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=42,\n",
        "        max_iter=2000,\n",
        "        tol=1e-4\n",
        "    ))\n",
        "])\n",
        "\n",
        "pipeline.fit(x_train, y_train)\n",
        "print(\"Model trained successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE-oCVV0b4Pa",
        "outputId": "c6cc817c-ba92-407c-8d6c-32919d774c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 4: Training Model ---\n",
            "Model trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Model Evaluation"
      ],
      "metadata": {
        "id": "CBjUkfEjfrI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Step 5: Model Evaluation ---\")\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "y_pred = pipeline.predict(x_test)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJnaGRuQcByU",
        "outputId": "af57ba78-0a97-4d3a-8148-76c494e780d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 5: Model Evaluation ---\n",
            "Accuracy: 0.9528\n",
            "\n",
            "Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "        Not Offensive       0.93      0.98      0.95      6186\n",
            "Offensive/Hate Speech       0.98      0.93      0.95      6186\n",
            "\n",
            "             accuracy                           0.95     12372\n",
            "            macro avg       0.95      0.95      0.95     12372\n",
            "         weighted avg       0.95      0.95      0.95     12372\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Saving and loading Model"
      ],
      "metadata": {
        "id": "8aoiqypnftha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "t51xYzxycGL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'hsd_model.sav'\n",
        "pickle.dump(pipeline, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "GjTEfgRAgdzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading\n",
        "loaded_model = pickle.load(open('hsd_model.sav', 'rb'))"
      ],
      "metadata": {
        "id": "F2117IZjhu14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Interactive Prediction"
      ],
      "metadata": {
        "id": "TF9Wg3OldaYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Step 7: Interactive Prediction ---\")\n",
        "positive_words = {\"love\", \"nice\", \"good\", \"happy\", \"great\", \"friend\", \"beautiful\"}\n",
        "\n",
        "def custom_predict(text):\n",
        "    base_pred = pipeline.predict([text])[0]\n",
        "    proba = pipeline.predict_proba([text])[0]\n",
        "\n",
        "    # Positive safeguard\n",
        "    if any(word in text.lower() for word in positive_words):\n",
        "        not_off_idx = list(pipeline.classes_).index(\"Not Offensive\")\n",
        "        if proba[not_off_idx] < 0.6:\n",
        "            base_pred = \"Not Offensive\"\n",
        "\n",
        "    return base_pred, dict(zip(pipeline.classes_, proba))\n",
        "\n",
        "print(\"Enter a phrase to check if it's hate speech (type 'quit' to exit):\")\n",
        "while True:\n",
        "    user_input = input(\"Enter text: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "    pred, probas = custom_predict(user_input)\n",
        "    print(f\"\\nPrediction: {pred}\")\n",
        "    print(\"Confidence Scores:\")\n",
        "    for label, prob in probas.items():\n",
        "        print(f\"  {label}: {prob:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyvJypQMcNKx",
        "outputId": "8ded85f5-04cc-4056-a381-d49a8dabfdf4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Step 7: Interactive Prediction ---\n",
            "Enter a phrase to check if it's hate speech (type 'quit' to exit):\n",
            "Enter text: i really love to eat fruits\n",
            "\n",
            "Prediction: Not Offensive\n",
            "Confidence Scores:\n",
            "  Not Offensive: 0.6475\n",
            "  Offensive/Hate Speech: 0.3525\n",
            "Enter text: quit\n"
          ]
        }
      ]
    }
  ]
}